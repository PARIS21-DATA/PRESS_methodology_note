--- 
title: "Methodology for measuring and estimating funding to data and statistics"
description: "Technical note for the Partner Report on Support to Statistics"
author: 
  - Yu Tian, [PARIS21](https://paris21.org/about-paris21/our-team/yu-tian)
  - Archita Misra, [PARIS21](https://www.paris21.org)
#date: "`r Sys.Date()`"
site: bookdown::bookdown_site
header-includes:
  - \usepackage{caption}
  - \usepackage{array}
  - \usepackage{float}
  - \hypersetup{colorlinks = true, urlcolor = cyan, citecolor = black, menucolor = black, anchorcolor = black, linkcolor=black}

favicon: "P21_icon.ico"
bibliography: Bibliography.bib
link-citations: true
keywords:
  - PRESS
  - Statistics
  - 2022
---


# Acknowledgements {-}

Draft  methodological  note  prepared  by  Yu  Tian  and  Archita  Misra  (PARIS21)  under  the  supervision  of  Rajiv 
Ranjan (PARIS21). The authors are grateful to Eric Swanson and Lorenz Noe (Open Data Watch) and Simon Lange 
(OECD)  for  their  valuable  review  and  feedback.  Further  comments  to  the  authors  (Yu.Tian@oecd.org; 
Archita.misra@oecd.org) are welcome.


<!--chapter:end:index.Rmd-->

# Background

PARIS21 produces the Partner Report on Support to Statistics (PRESS) annually to report on trends in 
support  to  statistics.  The  methodology  is  applied  retrospectively  for  all  previous  years  to  ensure 
comparability over time. This document presents the methodology.  

<!--chapter:end:01-Background.Rmd-->

#  Monitoring funding to statistics with accuracy

This section provides information on how to monitor support to statistics and how the data of the 
PRESS, which is also used  for  reporting SDG indicator 17.19.1  ("Dollar Value of all  resources made 
available to strengthen statistical capacity in developing countries"), is generated.  

Prior to PRESS 2018, the PRESS only focused on borrowing countries of the International Development 
Association.^[Eligibility for IDA support depends first and foremost on a country’s relative poverty, which is defined as GNI per capita 
below an established threshold and updated annually ($1,185 in the fiscal year 2021). IDA also supports some countries, 
including several small island economies, that are above the operational cut‐off but lack the required creditworthiness to 
borrow from the International Bank for Reconstruction and Development (IBRD). For more information, see: https://ida.worldbank.org/en/about/borrowing-countries]
Since 2018, the PRESS covers the commitments received by all countries throughout the 
report  to  align  the  findings  with  the  SDG  indicator  17.19.1:  "Dollar  value  of  all  resources  made 
available to strengthen statistical capacity in developing countries". Commitments were used as the 
main measurement instead of disbursements from the beginning of PRESS in 2006, when commitment 
data  entries  were  made  available  more  consistently.  See  section \@ref(estimating-using-CRS)  for  a  discussion  on  using commitments vs disbursements in detail. 

The PRESS aims to provide a full picture of international support to statistics. To achieve this goal, it 
mainly takes advantage of two data sources:


## OECD's Creditor Reporting System (CRS)

The Organisation for Economic Co‐operation and Development (OECD)’s Creditor Reporting System
(CRS) records data from OECD Development Assistance Committee (DAC) members (donors) and some
non‐DAC donors. This provides a comprehensive account of Official Development Assistance (ODA).
Donors report to the CRS using specific codes for the sectors targeted by their aid activity. Statistical
Capacity Building (SCB) is designated by the sector code 16062.^[Until 2019, this purpose was vaguely defined as "Both in national statistical offices and any other government ministries". However, after a successful campaign to improve the description, this purpose is now defined as “All statistical activities, such as data collection, processing, dissemination and analysis; support to development and management of official statistics
including demographic, social, economic, environmental, and multi‐sectoral statistics; statistical quality frameworks;
development of human and technological resources for statistics, investments in data innovation."]
Each activity reported in CRS can only be assigned with one of the over 100 purpose codes.^[In recent years, CRS reporters can also assign multiple voluntary purpose codes to the same project. Code 16062 is not a voluntary code. See the CRS code list for more information: https://www.oecd.org/dac/financing-sustainable-development/development-finance-standards/dacandcrscodelists.htm] 
While CRS is one of the most reliable and comprehensive databases that accounts for aid flows, there are some concerns that need to be
addressed while compiling support for data and statistics, such as: the cross‐cutting nature of projects
with statistical components, limited reporter knowledge about the code, the assignment of some ODA
for data and statistics under other codes, lack of granularity in reporting, etc. These issues are covered
in detail in PARIS (2019). PARIS21 is seeking to reduce this usually downward bias using a text analysis
methodology (see section \@ref(machine-learning)).

The CRS identifies a project donor by looking at the source of the funding. Countries are identified as
donors if the flow is directly between them and the recipient country (type 1 in Fig. \@ref(fig:funding-flows)), or if
the flow is earmarked for a certain project and channeled through multilateral organisations (type 3
in Fig. \@ref(fig:funding-flows)). If a project is funded by un‐earmarked core contributions to multilateral
organisations, the donors are marked as the multilateral organisations (types 2 and 4 in Fig. \@ref(fig:funding-flows)).

```{r funding-flows, echo=FALSE, fig.align="center", fig.cap = "Flow of official aid in CRS.", out.width="60%" }
knitr::include_graphics("./images/CRS_funding_flow.png")
```


## PARIS21's annual online survey {#P21-online-survey}

The PARIS21 Secretariat supplements the data from the CRS with an annual online survey that is
completed by a global network of respondents, mostly non‐DAC donors. The survey covers a subset
of the variables collected in the CRS, as well as some additional variables specific to data and statistics.
Responding to the online survey is voluntary and offers an opportunity for respondents to share
information about their statistical activities. Respondents include non‐DAC members, including non‐
DAC donor countries, multilateral organisations, regional statistical training institutes, and other
philanthropic organisations. The percentage of these projects in the final PRESS database has
decreased in recent years, as many multilateral organisations have improved the granularity of their
reporting to the CRS, making these data equally useful as data collected from the PRESS survey. To
reduce the burden on donors, these multilateral organisations are no longer required to fill in the
PRESS survey.

<!--chapter:end:02-Monitoring-funding-to-statistics-with-accuracy.Rmd-->

# Identifying data and statistical projects using machine learning {#machine-learning}

The developed method to identify data and statistical projects is based on a two-step procedure that analyzes project titles in the first step by detecting pertinent keyword (**A**) and evaluates project’s detailed descriptions using a machine learning approach (**B**).

## Reading the CRS data

After downloading all .txt files for the years 2006 - 2020 from the official OECD [data base](https://stats.oecd.org/DownloadFiles.aspx?DatasetCode=CRS1), the fully merged data set is stored.


## Preparing the data 

Here, the process of preparing the data is outlined (see Fig. \@ref(fig:data-preparation-CRS) for a comprehensive overview).

1. **Reducing the full CRS data set**

    A known characteristic of Canadian reporting in the CRS data base is that both project titles and long descriptions^[Originally both short and long description present in CRS data; from now one referred to as description] are reported in both official languages in the format "Englisch/French". To avoid misclassification and misidentification due to the presence of both languages, the French part was dropped. Additionally, the full data set was reduced to 16 necessary variables to avoid heavy computational load of the full 96-variable data set. 

2.	**Adding text identifiers**

    i. *Text cleaning*: First of all, the titles and descriptions were lowercased and cleaned by removing all numbers and punctuation signs in an effort to prepare the text for the creation of unique text identifiers. This is done to avoid unnecessary inclusion of projects that differ only slightly (e.g. by a number or comma).  
    
        ```{r title-cleaning, results="asis", eval = FALSE}
        library(tm)
        
        # Define function to clean titles
        clean_titles <- function(title){
          title <- title %>% 
            removeNumbers %>%
            removePunctuation(preserve_intra_word_dashes = TRUE) %>%
            tolower
          return(title)
        }
        
        df_crs <- df_crs_raw %>%
          mutate(projecttitle = clean_titles(projecttitle),
                 shortdescription = clean_titles(shortdescription),
                 longdescription = clean_titles(longdescription))
        ```
    <br />
    
    ii.	*Id creation*: Each project title and description is given a specific id in order to be able to analyze only distinct titles and descriptions later on. These were created using a well-known hashing algorithm called “xxHash” that is reasonably fast and exhibits very good collision properties (see https://github.com/Cyan4973/xxHash). 
    
        ```{r id-creation, results="asis", eval = FALSE}
        library(digest)
          
        df_crs <- df_crs %>%
          rowwise() %>% # use rowwise operations since digest concatenates vector of strings
          mutate(text_id = digest::digest(longdescription, algo = "xxhash32")) %>% # add text_id as hashed longdesription
        ```
      <br />
  
    iii. *descr2mine*: Due to lazy reporting, frequently the descriptions differ only marginally from the project titles. This would pose a problem to the previously outlined twofold procedure since descriptions that are identical to the project titles would be analyzed twice. Therefore, only distinct descriptions are used which are identified using the [Damerau-Levenshtein-Distance](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance) that counts how many alterations it would take to align both texts. The threshold for the maximal distance was set to 10 since this includes spelling mistakes, as well as one-word deviations (e.g. Output: …). 
    
          ```{r descr2mine, results="asis", eval = FALSE}
          library(stringdist)
                  
          # Max string distance underneath which strings can be considered the same/differing just by a word
          max_string_dist <- 10 
          df_crs <- df_crs %>%
            mutate(descr2mine = ifelse(stringdist(projecttitle, longdescription) < max_string_dist | str_count(longdescription) < 3, 
                                       NA, 
                                       longdescription))
          ```
      <br />
  
    iv. *Crating identifiers*: The CRS data set contains information about purpose of the funding flow in form of the purpose code, as well as other valuable information in other markers such as the gender marker (add link to resource) or the certain channel codes (41146 for UN Women). Table 1 lists all added identifiers. 
    
        ```{r identifier, results="asis", eval = FALSE}
        df_crs <- df_crs %>%
          mutate(scb = ifelse(purposecode == 16062, 1, 0), # Statistical capcity building identifier
                 pop = ifelse(purposecode == 13010, 1, 0), # population policy identifier
                 gen_ppcode = ifelse(purposecode %in% c(15170:15180), 1, 0), # add gender purpose code identifier
                 gen_marker = ifelse(gender == 1 & !is.na(gender), 1, 0), # add gender marker (0 - no gender, 1 - primary purpose, 2 - secondary)
                 gen_donor = ifelse(channelcode == 41146, 1, 0), # all projects from UN Women
                 gen_sdg = str_detect(sdgfocus, "^5|,5")) # SDG 5: Gender equality
        ```
      <br />
    
  
```{r data-preparation-CRS, echo=FALSE, fig.align="center", fig.cap = "Diagram of the data preparation process.", out.width="100%" }
knitr::include_graphics("./images/data_preparation_CRS.png")
```

## **A**: Title pattern matching

In the following, the process of matching pertinent keywords in project titles is outlined (see Fig. \@ref(fig:title-pattern-matching) for a comprehensive overview).

1. **Preparing the data**

    In the first step, the language of both title and description is detected using [Google’s Compact Language detector 2](https://github.com/CLD2Owners/cld2) (CLD2). It can detect 83 different languages and exceeds similar language detection engines by as much as 10x in speed. Analyzing the language distribution is crucial to a refined classification since text in every language has to be treated differently, using different keywords for the subsequent title pattern matching and fitting a different machine learning model later on. Therefore, the procedure was applied to projects in English, French, Spanish and German since these make up the majority of detected languages. This was implemented by selecting only projects with combinations of (title_language, long_language) in (en, fr, es, de, NA) x (en, fr, es, de, NA) while excluding the (NA, NA) combination. This combination was excluded since CLD2 in a vast majority of cases detects NA if the text is very short or nonsensical.

    To give an overview how many projects are analyzed using this method, this approach encompasses 3.145.387 (90.6%) projects while 23.4020 	(6.7%) were excluded for being (NA, NA) projects. That leaves 90241 (2.6%) projects that were excluded because they were either wrongly detected or belong to some minor reporting languages (e.g. Norwegian, Portuguese or Polish with a significant fraction within the 2.6% of excluded projects).  

    In the second step, duplicated project titles were dropped to analyze these titles only once during the title pattern matching procedure which again reduced computation time.

```{r title-matching-language, results="asis", eval = FALSE, indent = '    '}
# All languages to include in classification - options: en, fr, es, de
languages <- c("en", "fr", "es", "de")
        
# Add unique title id and detect language of title and long description
df_crs <- df_crs %>%
  mutate(projecttitle_lower = tolower(projecttitle)) %>%
  rowwise() %>% # use rowwise operations since digest concatenates vector of strings
  mutate(title_id = digest::digest(projecttitle_lower, algo = "xxhash32")) %>% # create title id to drop duplicated titles later
  ungroup() %>%
  mutate(title_language = cld2::detect_language(projecttitle)) %>%
  mutate(long_language = cld2::detect_language(longdescription))
        
# Use only projects in en, fr, es and de
df_crs <- df_crs %>%
  filter(title_language %in% c(languages, NA) & long_language %in% c(languages,NA)) %>%
  filter(!is.na(title_language) | !is.na(long_language)) # omit projects with both languages NA 
        
# Select necessary columns and drop projects with duplicated title ids 
df_crs <- df_crs %>%
  select(title_id, projecttitle, projecttitle_lower, longdescription, title_language, long_language) %>%
  filter(!duplicated(title_id))
```
        
      <br />

2. **Title pattern matching**

    i. *Clean and lemmatize keyword lists*: For the treatment of the minority languages (French, Spanish and German), the English keyword list for statistics was translated by experts working in the field of official statistics. It contains many aspects of official development assistance in statistics and can be found in Appendix \@ref(Appendix-A). The keywords therein are chosen in a way that it is almost certain that a project is at least partly related to statistics if its title contains one of the keywords. The same was done for the English list of acronyms which can differ in other foreign languages. Together with the list for mining projects, the keyword lists were cleaned and lemmatized to guarantee that they will be matched to cleaned and lemmatized words occurring in project titles. 
    
        ```{r clean-lemmatize-keywords, results="asis", eval = FALSE}
        # list_keywords_stat, list_acronyms and demining_small_arms previously loaded
        
        # Define lemmatization function
        clean_and_lemmatize <- function (string){
          string <- string %>% 
            tolower %>% 
            removeWords("'s") %>% # remove possesive s so that plural nouns get lemmatized correctly, e.g. "women's"
            removeNumbers() %>%
            removePunctuation(preserve_intra_word_dashes = TRUE) %>%
            stripWhitespace %>% 
            removeWords(c(stopwords('english'))) %>% 
            removeWords(c(stopwords(source = "smart")[!stopwords(source = "smart") %in% "use"])) %>% # exclude "use" from smart stopwords 
            lemmatize_strings()
        }
        
        # Lemmatization for "en"
        list_keywords_stat <- clean_and_lemmatize(list_keywords_stat)
        demining_small_arms <- clean_and_lemmatize(demining_small_arms)
        
        # Stemming for minority languages "fr", "es" and "de"
        list_keywords_stat <- stem_and_concatenate(list_keywords_stat, language = lang)
        demining_small_arms <- stem_and_concatenate(demining_small_arms, language = lang)
        ```
      <br />
    
    ii.	*Clean and lemmatize titles*: Cleaning of project titles was achieved by removing numbers, punctuation and so called “stopwords” (e.g. “and”, “the”, “for”) since they don’t contain information towards the classification. Subsequently, words were lemmatized meaning to reduce different forms of a word to its lemma (e.g. “women”, “woman’s”, “woman” -> “woman”). This is very important to guarantee that all various versions are found during the title pattern search. For minority languages however, stemming is used instead of lemmatization since no good lemmatization implementation was available.
    
        ```{r cl-lemma-titles, results="asis", eval = FALSE}
        df_crs <- df_crs %>%
          mutate(projecttitle_clean = ifelse(title_language == lang & !is.na(title_language), 
                                             clean_and_lemmatize(projecttitle_lower),
                                             projecttitle_clean)) %>%        
        ```
      <br />

    iii. *Keyword detection*: For every language, the project title was analyzed whether it contains one of the statistical keywords or acronyms. Note that statistical keywords were detected within cleaned and lemmatized titles whereas for acronyms, the original title was used since the lemmatization and stemming algorithms were found to change acronyms. 
    
          ```{r keyword-detection, results="asis", eval = FALSE}
          # Create regex for searching titles 
          list_keywords_stat <- paste0(" ", paste(list_keywords_stat, collapse = " | ")," |^", # words with whitespaces
                                      paste(list_keywords_stat, collapse = " |^")," | ", # beginning of string
                                      paste(list_keywords_stat, collapse = "$| "), "$") # end of string
                                      
          list_acronyms <- paste0(" ", paste(list_acronyms, collapse = " | ")," |^", 
                            paste(list_acronyms, collapse = " |^")," | ", # beginning of string
                            paste(list_acronyms, collapse = "$| "), "$") # end of string
          
          demining_small_arms <- paste0(" ", paste(demining_small_arms, collapse = " | ")," |^", 
                                    paste(demining_small_arms, collapse = " |^")," | ", # beginning of string
                                    paste(demining_small_arms, collapse = "$| "), "$") # end of string
                                
          # Detect stat, acronyms and mining 
          df_crs <- df_crs %>%
            mutate(match_stat = ifelse(title_language == lang | is.na(title_language), 
                                       str_detect(projecttitle_clean, list_keywords_stat), 
                                       match_stat),
                   mining = ifelse(title_language == lang | is.na(title_language),
                                   str_detect(projecttitle_clean, demining_small_arms),
                                   mining)) %>%
            mutate(match_stat = ifelse(title_language == lang | is.na(title_language),
                                       str_detect(projecttitle_lower, list_acronyms) | match_stat,
                                       match_stat))
          ```
      <br />
 
    iv. *Merging classes for final filter*: The reason to detect also mining projects was to exclude those projects from the statistics filter since expressions like “small arms survey”, “survey of landmine situation” make frequent appearances in project titles but are not related to statistics. Hence, only projects for which a statistical keyword was detected but no mining keyword are marked as a statistical project in the pattern matching step.
    
        ```{r class-merging, results="asis", eval = FALSE}
        # Exclude mining projects, since they contain survey -> not statistical project
        df_crs <- df_crs %>%
          mutate(text_detection_wo_mining = match_stat & !mining) %>% 
          mutate(text_detection_wo_mining_w_scb = match_stat | scb)
        ```
      <br />

    
Lastly, the statistics filter is added back to the reduced data set according to the title id. This ensures that all projects with the same title in the reduced data set are marked as statistical by the title pattern matching.

```{r title-pattern-matching, echo=FALSE, fig.align="center", fig.cap = "Schematic diagram of the title pattern matching.", out.width="100%" }
knitr::include_graphics("./images/title_pattern_matching.png")
```

## **B**: Text mining of long descriptions

Lastly, the process of applying a machine learning approach to classify the projects' long descriptions will be explained in detail (see Fig. \@ref(fig:text-mining) for a comprehensive overview).

1.	**Preparing the data**

    i. *Language filtering*: For the preparation of the data, the reduced data set with the additional statistics filter from the pattern matching is filtered according to the description language to ensure that the text mining is applied only to text in one language. Note that there are projects with differing title and description language (frequently English title, minority language description) which is however no problem, since a project’s description can be assumed to be statistical even when its title is in another language. 
    
        ```{r B-lang-filtering, results="asis", eval = FALSE}
        lang <- "en"
        
        # Filter only projects with description language lang
        df_crs <- df_crs_reduced %>%
          filter(long_language == lang)
        ```
      <br />

    ii. *Manual filter correction*: For 200 English projects, the description of projects, which were detected as statistical projects by the title pattern matching, were verified manually by experts. It can be the case that a projects title refers to statistics (e.g. "census aid") while its description contains no relevant information towards a classification (“Material and equipment for on the ground operations”). This additional step makes sure that the learning set contains less errors and hence increases the accuracy. 
    
        ```{r B-manual-correction, results="asis", eval = FALSE}
        # Read manually verified projects 
        man_verified <- readRDS("./Data/Manually verified/stat_projects_verified.rds")
        
        df_crs <- df_crs %>%
          filter(!is.na(descr2mine)) %>%
          select(text_id, description = descr2mine, longdescription, class_filter = text_detection_wo_mining_w_scb) %>%
          left_join(man_verified %>% select(longdescription, match_stat), by = "longdescription") %>% # add manually verified
          mutate(class_filter = ifelse(!is.na(match_stat), match_stat, class_filter)) %>% # replace class filter with manually verified filter
          select(-longdescription, -match_stat)
        ```
      <br />
 
    
    iii. *Drop duplicated text ids*: As for the title ids, duplicated text ids are dropped to reduce the computational load during the text mining. In addition, some projects shared a discription but differed in their title. If one of the projects was detected as `TRUE` and one as `FLASE` in step **A**, both of them were discarded to reduce errors in the training set later on.  
    
          ```{r B-drop-duplications, results="asis", eval = FALSE}
          df_crs <- df_crs_reduced %>%
            filter(!is.na(descr2mine)) %>%
            distinct() %>%
            group_by(text_id) %>% # remove all ambiguous projects (same description, one FALSE one TRUE)
            filter(n() == 1) %>% 
            ungroup() %>%
            as.data.frame
          ```
      <br />

    
2. **Text mining of long description**

    i. *Construct learning and prediction set*: For this machine learning approach, it is necessary to construct a balanced learning set which contains 50% negatively marked (NM) and 50% positively marked (PM) projects. The projects detected in Step **A** are used as the PM projects since it is reasonable to assume that if the title contains statistical keywords, also its description refers to statistics. The NM projects are chosen randomly because it can be assumed that only a small fraction of projects refer to statistics and therefore the probability to introduce error into the learning set is very small. The prediction data set contains simply the rest of the NM projects in the text mining data set. 
    
        ```{r B-learning-set, results="asis", eval = FALSE}
        # Define parameters 
        frac_pred_set <- 1             # use only x% of full prediction set to speed up for testing
        full_learning_percent <- 1     # take only x% of full learning set size if too large for RAM
        neg_sample_fraction <- 1       # fraction of NM to PM in learning set
        
        # Get size of PM projects in learning set
        size_positive_train <- neg_sample_fraction * full_learning_percent * df_crs %>% filter(class_filter == TRUE) %>% nrow
        
        # Construct prediction set
        pred <- df_crs %>%
          filter(class_filter == FALSE | is.na(class_filter)) %>%
          sample_n(size = frac_pred_set * n())
        
        # Error: if size of pred smaller than size of PM projects, not possible to construct training set
        if(pred %>% filter(!is.na(class_filter)) %>% nrow < size_positive_train) stop("Pred not large enough to create learning set! Choose a larger frac_pred_set")
        
        # Construct training set
        learning <- df_crs %>%
          filter(class_filter == TRUE) %>%
          sample_n(size = n()*full_learning_percent) %>%
          rbind(pred %>% filter(!is.na(class_filter)) %>% sample_n(size = size_positive_train)) # add same amount of NM project from pred
        
        # Exclude NM projects in training set from pred
        pred <- pred %>%
          filter(!text_id %in% train$text_id)
        ```
      <br />

    
    ii. *Clean and lemmatize descr2mine*: As previously discussed, only distinct long descriptions (distinct from title) are used to avoid analyzing the same text twice. These are then cleaned and lemmatized to reduce the text to the relevant information. 
    
        ```{r B-clean-descr2mine, results="asis", eval = FALSE}
        # Set languages for stemming and lemmatization
        stem_languages <- c("de", "fr", "es")
        lemma_languages <- c("en")
        
        # Change original description with cleaned description
        if (lang %in% lemma_languages) {
          learning$text_cleaned <- clean_and_lemmatize(learning$description)
          print("Start lemmatize pred")
          pred$text_cleaned <- clean_and_lemmatize(pred$description)
          print("Finished lemmatization pred")
        } else if (lang %in% stem_languages) {
          learning$text_cleaned <- stem_and_concatenate(learning$description, language = lang)
          pred$text_cleaned <- stem_and_concatenate(pred$description, language = lang)
        }
        ```
      <br />
 
    
    iii. *Create DTM matrices*: After splitting the learning set into the training set and testing set in a ration of 80/20, the document term matrix (DTM) is created for the training set. It has all the words that are present in all descriptions of the training data set (terms) as columns and collects their weighted frequency for each project in the respective row. For creating the DTMs of the test data and prediction data, terms occurring in the training data DTM are used which means that the all DTMs share the same columns. This is important for the prediction step later on since the model is only trained on these terms and assigns a relative weight to each of them. Therefore, it can only predict on terms that has already “seen”. 
    
          ```{r B-DTM-matrices, results="asis", eval = FALSE}
          # Take 80% training data, 20% testing data
          dt <- sort(sample(nrow(learning), nrow(learning)*0.8))
          train_data <- learning[dt,]
          test_data <- learning[-dt,]
          
          # Construct DTMs 
          train_data_dtm <- train_data$text_cleaned %>% VectorSource() %>% VCorpus() %>% DocumentTermMatrix(control = list(weighting = weightTf))
          dictionary_dtm <- Terms(train_data_dtm) # use only terms appearing in training data to construct test and pred DTM
          test_data_dtm <- test_data$text_cleaned %>% VectorSource() %>% VCorpus() %>% DocumentTermMatrix(control = list(weighting = weightTf, dictionary = dictionary_dtm))
          prediction_data_dtm <- pred$text_cleaned %>% VectorSource() %>% VCorpus() %>% DocumentTermMatrix(control = list(weighting = weightTf, dictionary = dictionary_dtm))
          
          ```
      <br />

    
    iv. *Training the XGBoost model*: The model is obtained from the regularizing gradient boosting framework [XGBoost](https://xgboost.readthedocs.io/en/stable/index.html) by fitting the training data. Due to the broad literature on this machine learning approach, a detailed discussion shall be refrained from here. It can be said however that by passing along the training data DTM alongside the correct classification labels, the XGBoost model identifies the most important words appearing in the PM projects and assigns a high importance to them (see Fig. \@ref(fig:importance-matrix) below). 
    
        ```{r B-XGBoost, results="asis", eval = FALSE}
        # Set the labels for class_filter
        label.train <- as.numeric(train_data$class_filter)

        # Training parameters
        eta_par <- 0.1
        nrounds_par <- 5 / eta_par
        
        # Train the model
        fit.xgb <- xgboost(data = as.matrix(train_data_dtm), label = label.train, max.depth = 17, eta = eta_par, nthread = 2, 
                           nrounds = nrounds_par, objective = "binary:logistic", verbose = 1)
        ```
      <br />

    
    v. *Testing and prediction*: The model is then assessed using the test data. Since the model returns a score p_stat in the range from 0 to 1 whether a project’s description refers to statistics, different thresholds are tested to see how the model performs (more in Appendix \@ref(Appendix-B)). Finally, all projects in the prediction set are predicted using the fitted model. If a project receives a score of $p_{stat} \geq 0.9$, it is marked as statistical by the text mining (justification of threshold). 
    
        ```{r B-testing, results="asis", eval = FALSE}
        # Predict test and pred data
        test.xgb <- predict(fit.xgb, as.matrix(test_data_dtm))
        pred.xgb <- predict(fit.xgb, as.matrix(prediction_data_dtm))
        
        # Set all projects to 1 for a score higher than 0.9
        threshold <- 0.90
        test_data <- mutate(test_data, predictions = ifelse(predictions_raw > threshold, 1, 0))
        pred <- mutate(pred, predictions = ifelse(predictions_raw > threshold, 1, 0))
        
        # Show accuracy
        accurracy <- mean(test_data$predictions == test_data$class_filter)
        print(accurracy)
        ```
      <br />

  
    vi. *Iteration of step i.-v. for learning set robustness*: In step 1, the 50% NM projects were chosen at random since the probability that statistical project is in this set is very small. However, it could still be the case that the statistical projects are included by chance. This can be almost avoided by repeating steps 1. – 5. with a training set that is constructed using only projects that are predicted not to be statistical with $p_{stat} \leq 0.3$. This threshold is chosen because it makes sure that the training set is only constructed from true NM projects while not being too restrictive and potentially introducing a bias into the training set (e.g. if all projects with $p_{stat} \leq 0.05$ stem from the agriculture sector). On average, this iterative procedure increases the accuracy by 5% - 10% depending on the size of the prediction set. 
    
        ```{r B-iteration, results="asis", eval = FALSE}
        # Filter projects with low score 
        pred_negative <- pred %>% 
          filter(predictions_raw <= 0.3) %>%
          sample_n(size = size_positive_train) %>% 
          select(text_id, description, class_filter) 
        
        # Construct new learning set with low-score projects as NM
        learning <- df_crs %>%
          filter(class_filter == TRUE) %>%
          sample_n(size = n()*full_learning_percent) %>%
          rbind(pred_negative) %>%
          filter(!is.na(class_filter))
        
        # Construct pred from all NM projects that are not in the training set
        pred <- df_crs %>%
          filter((class_filter == FALSE | is.na(class_filter)) & !(text_id %in% pred_negative$text_id)) %>%
          sample_n(size = frac_pred_set * n()) #use only frac_pred_set% to speed up for testing
          
        # Repeat step i. - v.
        ```
      <br />
 
    
Finally, the text mining filter is added back to the reduced data set according to the text id. This ensures that all projects with the same description in the reduced data set are marked as statistical by the text mining methodology.
    
```{r text-mining, echo=FALSE, fig.align="center", fig.cap = "Schematic diagram of the text mining.", out.width="100%"}
knitr::include_graphics("./images/text_mining.png")
```


```{r importance-matrix, echo=FALSE, fig.align="center", fig.pos = "!H", fig.cap = "Relative importance assigned to terms appearing in long descriptions.", out.width="70%" }
knitr::include_graphics("./images/importance_matrix.png")
```

  

<!--chapter:end:03-Identifying-data-and-statistical-projects-using-machine-learning.Rmd-->

# Monitoring funding to statistics with reduced reporting lag

## What is the reporting lag?

The workflows for combining the two main data sources of PRESS are described in Fig. \@ref(fig:reporting-lag).

One key step when merging the PRESS data, reported by both donors and implementors, with the CRS
data is avoiding duplication in a donor‐implementor‐recipient funding flow. To achieve this, the
projects are examined against their unique identifier in both sources. The projects reported by
implementers (mostly from the PRESS survey) are not counted as contribution of the reporting
agencies. These projects are counted as projects by the donor agencies, after duplication checks were
applied when merging the projects reported by implementers and the projects reported by donors.
As the data and final report of PRESS depend in large part on the CRS database, which has a 12‐months
lag in coverage, the previous editions of PRESS did not capture timely donor financial flows to
statistics, leading to a structural lag in reporting.

```{r reporting-lag, echo=FALSE, fig.align="center", fig.cap = "How the lag in the CRS data led to a lag in previous rounds of PRESS.", out.width="100%" }
knitr::include_graphics("./images/reporting_lag.png")
```

This lag meant that in its previous format, PRESS could not provide timely information for partners in
data and statistics, including:

  - Nowcasting the funding to statistics
  
  - Forecasting funding to statistics

Hence, despite the many improvements in PRESS over the years, the lack of timely aid reporting is a
persistent concern among its primary users, especially development aid providers. With a growing
interest in supporting data and statistics, there is an increasing demand for timely data to plan
activities and projects and coordinate development co‐operation efforts. This issue has become
particularly urgent in light of the coordinating efforts to fund the Cape Town Global Action Plan for
Sustainable Development Data (CT‐GAP),^[See https://unstats.un.org/sdgs/hlg/cape-town-global-action-plan/] as well as in the context of a diverse data ecosystem comprising new actors.

PARIS21 addressed this request in its 2019 annual meeting by introducing the concept of a
methodology extension. While the PRESS methodology will still be used to report information until 18
months before the publication, the methodology extension will provide stakeholders with PRESS‐like
information on more recent periods, therefore reducing the reporting lag significantly. This concept
became more relevant in 2020, when the development co‐operation community had to face the
challenges that arose due to the COVID‐19 pandemic in national statistical systems [@PARIS21-Covid]
and funding to data by domestic and external stakeholders [@PRESS-2021].


## Estimating up‐to‐date support to statistics using CRS {#estimating-using-CRS}

While the previous PRESS (from 2008 to 2019) captured the support to data and statistics by looking
at global **commitments**^[A firm obligation, expressed in writing and backed by the necessary funds, which is undertaken by an official
donor. It provides specified assistance to a recipient country or a multilateral organisation. Bilateral
commitments are recorded in the full amount of the expected transfer, irrespective of the time required for the
completion of disbursements. Commitments to multilateral organisations are reported as the sum of (i) any
disbursements in the year reported on, which have not previously been notified as commitments, and (ii)
expected disbursements in the following year.] 
to statistics, the annual **disbursements**^[The release of funds to or the purchase of goods or services for a recipient; by extension, the amount spent. Disbursements record the actual international transfer of financial resources, or of goods or services valued at
the cost to the donor. In the case of activities conducted in donor countries, such as training, administration, or
public awareness programmes, disbursement is assumed to have occurred when the funds have been
transferred to the service provider or recipient. These may be recorded as gross (the total amount disbursed
over a given accounting period) or net (the gross amount, less any repayments of loan principal or recoveries
on grants received during the same period). It can take several years to disburse a commitment.]
received by a certain country are also informative for donors and countries when planning their activities, especially those short‐term
activities financed by a donor’s annual or biannual budget. Leveraging this additional variable allows
for the estimation of funding to data and statistics received by countries in the current and coming
years while still using the same base data, i.e., the CRS and PRESS surveys (and many other data
sources on development aid, see section 3), which include both variables for each project.

Looking at disbursements instead of commitments to estimate the support to data and statistics has
two distinct advantages:

  1. Disbursements capture the actual release of funds, so are more useful for donor planning purposes.
    
  2. It can take several years to disburse a commitment and some commitments are never
    disbursed. Hence, by design, there are more data points available on disbursements than
    commitments over the same time period. The additional data on disbursements allows for 
    better understanding of financing patterns and donor behaviour, leading to more robust data analysis.
    
This availability of more data points enables us to estimate support to statistics in the current year
(nowcasting) through robust regression analysis. It also provides more substantial evidence of funding
trends in the coming years (forecasting). The following sub‐sections will focus on how to arrive at
these estimates.


### Nowcasting: using commitments to predict current disbursements

Given that CRS has a lag of 12 months for reporting both disbursements and commitments, one way
we can estimate support to statistics disbursed in the current year is by looking at the relationship
between the two variables. The literature on aid predictability indicates that these two variables may
be closely related over time. A 2013 study examining aid predictability based on CRS data also shows
that commitments have a significant impact on disbursements five years after they were made
[@Hudson].

For most development projects reported to the CRS and the PRESS survey, both commitment and
disbursement data are reported. Even when these variables are not directly reported, however, the
missing value can usually be imputed.^[For example, the amount for technical support projects that do not have direct monetary transfers can be
replaced by a cost estimate by the provider. In cases where the disbursement information is missing, the
estimated disbursement amount can be calculated by dividing the unspent commitment amount using the
number of years left before the expected end date]

Using these two variables, PARIS21 has developed a simple linear regression model to estimate the
funding from donors based on historical data at activity level. Regression analysis was conducted to
predict current disbursements based on reported commitments, captured by
$Average\_Annual\_Spending$.

\begin{align*}
Disbursement &= Average\_annual\_spending \cdot k + d \\
\text{where} ~~~~ Average\_annual\_spending &= \text{Total Project Commitments}/number\_of\_years
\end{align*}


k is the regression coefficient and d is the error term. The number of years is the difference between
the start date and end date of a reported activity. Reported dates are used for activities with missing
value in those two variables. The analysis used the most recently accessible data from the CRS^[See https://stats.oecd.org/DownloadFiles.aspx?DatasetCode=CRS].

This model shows a correlation between disbursements and average spending. Average annual
spending is calculated based on the assumption that commitment without a detailed plan for
disbursement will be distributed evenly by year, from the expected start year to the end year of the
project.
          
                               Estimate       Std. Error       t value     Pr(>|t|) 
------                        ---------     ------------      --------    ---------
(Intercept)                      38.455          8.04901        ‐4.778      0.0139*
$Average\_Annual\_Spending$     0.87461          0.05191        12.997      0.0456*

Table: (\#tab:regression-table) Regression table from the analysis


The analysis of CRS data shows a significant correlation (90%) between disbursements and
commitments each year. The value of k and the predictability of the model vary depending on the
reporting pattern of each donor. For example, while the commitment numbers reported by most
donors each year are usually higher than disbursements (Fig. \@ref(fig:commitments-CRS) on the left), this is reversed in the case
of a few donors (Fig. \@ref(fig:commitments-CRS) on the right)^[This particular reverse correlation can be explained by different factors. Firstly, the financial crisis impacted the continuity of some donors’ ODA flow more than others. The significant variation of the exchange rate or inflation
rate of a donor could also lead to a sudden change in the converted constant value of aid. In addition, some
donors tend to make more long‐term commitments than others, resulting in a distribution of disbursements
over a long period of time, even after the donors had significantly reduced their overall international aid
package].

```{r commitments-CRS, echo=FALSE, fig.align="center", fig.show='hold', out.width="49%", out.height="20%", fig.cap = "Disbursements vs commitments reported in CRS (all donors) on the left. On the right, disbursements vs commitments in the CRS reported by the UK.", }
knitr::include_graphics(c("./images/commitments_disbursements_CRS.png", "./images/commitments_disbursements_UK.png"))
```

Using the above method, PARIS21 was able to nowcast the funding to statistics in years that the most
recent CRS data yet to cover. For instance, although the CRS data available in early 2020 only includes
full coverage of official aid until 2018, the nowcast is able to provide information on aid to statistics
including 2019 and 2020. This is because the stable relationship between average annual spending
and commitments is leveraged, which allows us to estimate the 2019 and 2020 disbursement values,
from the 2018 reported commitment values.

As a result, for the first time, the 2020 edition of PRESS presented information on funding to data and
statistics up to 2019, as opposed to two years prior as in editions including and before PRESS 2019.^[Due to the disruptive effect of the COVID‐19 pandemic on the predictability of the model, the nowcasting results for 2020, although produced, were not presented in the PRESS 2020 report.]


### Forecasting: anticipating future funding

The predictability of disbursements and commitments used for nowcasting funding to statistics
decreases greatly after the current year, since, for example, many projects which commenced in 2017
will end in 2020. However, this lack of predictability can be partially mitigated by the creation of a
forecasting model based on a few well‐informed assumptions, leveraging past PRESS data and
PARIS21’s institutional knowledge on support to statistics for over two decades. These assumptions,
which can lead to better forecasting quality, are described below:

  1. **Continuation of certain long‐standing projects**: We can assume that large projects such as
the support to the Demographic Health Survey driven by USAID, IMF’s national and regional
training on economic statistics, and the World Bank’s programme on statistical development
will remain stable in the near future. Significant changes on these programmes are also easier
to target and detectable. These projects are generally stable and attract similar spends each
year. Likewise, the upcoming censuses or major surveys in low‐income countries are expected
to be funded partially by donors.^[The COVID‐19 pandemic has brought great uncertainty to this assumption, especially for censuses planned
to take place between 2020 and 2021. Although funding for most censuses has been secured, many countries
have diverted their national budget to other, more urgent matters [@CCSA; @UNFPA], resulting in
the postponement of external funding] This information accounts for nearly half of the total
amount for data and statistics. Confirmation from donors of the continuation of these projects
can further improve the accuracy of this analysis.

  2. **Termination or reduction of funding for certain projects**: We can also anticipate the
termination or reduction for funding tied to a project based on its specific nature. For instance, 
the support for censuses is a one‐off disbursement and will not reoccur until the next census
round. Similarly, if a country become no longer eligible for ODA, graduate from IDA’s borrower
list or becomes an upper‐middle‐income country, it is then expected to receive a lower ODA
grant and become ineligible for some loans. In those cases, support for statistics might be
affected disproportionally, given its low priority.

It is also crucial to state that these predictions can only be accurate if the following additional
assumptions are met:

  - Development aid providers maintain their current levels of effort
  - Existing programmes continue to run
  - Commitments are fully disbursed
  - There is a response to prioritised needs such as censuses
  
The estimation is also limited if donors agencies publishing the new initiatives with a lag. The
predictability of both nowcast and forecast on funding to data and statistics also relies on aid providers
committing to maintaining the transparency and timeliness of their aid data. The forecasting looks at
contribution until $n+2$, given most international organisations’ work plan don’t go beyond that
horizon.

Due to the uncertainty caused by the COVID‐19 pandemic, the forecasting results from this
methodology were not presented in PRESS 2020. These will appear in the future PARIS21 publications
once more evidence becomes available.

In sum, the forecasting estimates should be interpreted with significant caution even if the above
model indicates a relative increase in the coming years. According to many historical estimates, the
funding gap for data and statistics (i.e. to find the entire CT‐GAP) is far from being closed. This gap is
likely to be exacerbated by the effects of the ongoing COVID‐19 crisis in large parts of the globe

## Expanding the PRESS database

### Exploring alternative data sources for aid flows on statistics

Apart from nowcasting and forecasting disbursements to statistics from PRESS data, another way to
address the structural lag in aid‐flow reporting can be by attempting to remedy the root cause of the
problem – the dependency on the CRS database – and searching for more timely information in
alternative data sources. PARIS21 has identified three main (types) of alternative data sources,
outlined below:

#### The International Aid Transparency Initiative (IATI) {-}

The IATI datastore is the largest alternative database outside of OECD‐DAC data for official
development assistance. With more than 100 donors reporting to this database, IATI has a much
shorter lag than CRS. It also covers more projects by philanthropic foundations. The COVID‐19
pandemic and the rising need for coordination has also incentivised aid providers to report to IATI
with less delay. However, IATI data suffer from a lack of quality assurance and inconsistency within
the dataset. Although it uses a similar data structure as the CRS, the reported projects in IATI may not
include important granular information, such as the project description. Furthermore, as many donors
only committed to reporting to IATI after 2014, the lack of historical data for drawing time series also
affects its ability to forecast.

#### Donors’ transparency portals {-}

In recent years, global donors have strengthened their efforts in aid transparency. Many donors have
developed online data portals or uploaded online datasets to share information on their aid projects,
especially the major donors in statistics such as the World Bank, UNDP, USAID, FCDO, IDRC, etc. These
datasets usually have a similar density of information as the CRS data and are usually updated more
frequently than CRS. However, the majority of donors still lack appropriate portals and public datasets.
Furthermore, merging these different datasets is possible, but time intensive.

PARIS21 has been exploring these data sources since 2019 and has accumulated knowledge over this
period. For example, the USAID dataset helped PRESS 2019 to identify the USA’s support to statistics
for the first time; in particular, its effort with the Demographic Health Survey (DHS). PARIS21 has also
established a methodology for merging and harmonising the aforementioned datasets. The
methodology maps variables in different datasets against each other and uses internal project
identifiers to avoid duplications.

#### Multilateral donors’ prospective reporting to the PRESS surve {-}

The online PRESS survey (introduced in Sec. \@ref(P21-online-survey)) includes a feature that allows donors to report on
future projects. Since many donors have a biannual programme of work, in each year’s survey, they
are encouraged to provide information on the project they have planned or committed to in the near
future. In the survey, donors can verify, edit, and cancel future projects in the next round of reporting.
However, previous editions of PRESS did not fully reflect future projects due to the report’s focus on
accuracy. However, these future projects could still contain valuable information to assist in the
projection of aid flows. The methodology developed by PARIS21 leverages these projects as an
underutilised existing data source that may not reflect completely on the activities from donors.
Nevertheless, it is useful for nowcasting funding.

The comparison of the above data sources can be found in \@ref(fig:data-sources). As another important data
source in the area of data and statistics, the Eurostat’s donor survey is analysed in Box 1.


```{r data-sources, echo=FALSE, fig.align="center", fig.cap = "Comparison of data sources.", out.width = "80%"}
knitr::include_graphics("./images/data_sources.png")
```


::: {.center data-latex=""}
**Box 1: The Eurostat’s Donor Survey – and why it is not included in the PRESS database**
:::

The annual Donor Survey by Eurostat aims to provide an overview of statistical projects in the
respective countries to allow for better planning of assistance in the field of statistics, to benefit
from acquired experience, and to avoid overlap. The survey is distributed to donor countries,
international organisations, and the recipients (mostly Eurostat member states or partner
states) of support to data and statistics.

According to the report of the 2020 round, the Donor Survey’s main objectives included:

  - facilitating better planning and prioritisation of assistance, especially amongst the donors;
      
  - increasing transparency/visibility for donors and implementing agencies and potentially serving as an “audit” document for beneficiaries;
      
  - providing the beneficiaries with a broad overview of the areas in which they are receiving support, also at regional level, and prioritising their future needs;
      
  - benefitting and learning from the experiences, good practices, and shortcomings of other projects;
      
  - facilitating a dialogue between beneficiaries, donors, and implementing agencies.
  
At donor country level and on the donors’ side, respondents to the Donor Survey overlap with
CRS. However, the CRS reporting is coordinated by one national focal point, while the Donor
Survey questionnaire is distributed to both the aid agencies and national statistics offices who
provide technical support. However, the Donor Survey data set does not have a good system to
harmonise the data from the two sides, nor does it contain the program identifiers, which
are essential to avoid duplication when combining information with other sources. Unlike the
development of financing databases, the Donor Survey also lacks a mechanism to update
previous years’ reported projects. Coverage of the survey is also not comprehensive enough to
provide additional values to the alternative data sources identified in this document.
:::::

### Addressing gaps in the alternative data sources

To take advantage of the alternative data sources, PARIS21 combined the information from CRS and
online surveys with these alternative data sources to create a more up‐to‐date, harmonised database
on funding for data and statistics. However, this means that two important problems must be
addressed, described below:

  1. **The completeness problem**: A common weakness of the alternative data sources,
compared with CRS, is their incomplete coverage. This is especially apparent in IATI where,
unlike CRS, donors may not report their full portfolio, leading to a lack of comprehensive
information (a “vertical” information gap i.e. multiple donors but incomplete project
information for individual donor). Furthermore, the CRS uses a more “centralized” reporting
system for each donor country, whereby information from different agencies providing ODA
is gathered under one entity before reporting to CRS as a whole. The IATI, on the other hand,
allows different agencies in a single donor country to report their data separately. This implies
different reporting patterns for different agencies based on their capacity to do so regularly,
and a lack of overall coordination.

  2. **The coverage problem**: CRS contains information from over 100 donors. On the other
hand, donor transparency portals suffer from a “horizontal” problem, i.e., they usually have
complete coverage and contain the full portfolio, but fewer than ten major donors provide
access to such open and easy‐to‐use databases.

PARIS21 has mitigated the horizontal and vertical problems in alternative data sources by harmonising
and linking these databases. The alternative sources provide a wider coverage, while the combination
of CRS, IATI and donors’ databases enhance the completeness of the data. The final data set used in
the analyses combines the alternative data sources and PRESS data using project IDs and other
identifiers. As a caveat, however, the total number of projects included in the alternative sources still
only represents 40% of all number of projects reported in the CRS.

The advantage of using such data sources, such as the timeliness and inclusion of philanthropic
foundations, makes them a useful extension of PRESS data, especially when trying to solve the lag
issue. However, their weaknesses imply that they are not a substitute for CRS or, by extension,
conventional PRESS analysis.


### Linking the alternative sources: the new harmonised database

The next step in leveraging the independent alternative data sources described above is to link them
with PRESS data and create a new harmonised database of disbursements for data and statistics **at
project level.**

Using disbursements as the primary variable to determine the support to statistics is even more
beneficial at this stage, and data on annual disbursements is adequately available in most of the
sources considered above. The activity‐based CRS data, for example, contain nowcasting/forecasting
regressions on this new data set by Simon etc. to see value add and/or consistency of our findings!
Should we present this? I think you did it and found little to no change right? disbursement information
for more than 98% of the projects. Similarly, the PRESS survey for multilateral donors provides specific
information on disbursement plans (though it is project‐based). The donors’ transparency portals are
also expenditure/disbursement based.

However, the IATI database is weaker in this regard: it contains an unusually high percentage of
negative commitments or disbursements. For example, data downloaded from the IATI database in
2018 contained negative value commitments or disbursements in 18% of projects reported^[Based on data collected in 2019, the future improvements of the IATI database have resolved this issue.]. In
comparison, less that 1% of activities reported in CRS has negative value, mostly associated with loan
repayments and correction of previous entries, i.e. not a database error.

For the harmonised database, the missing disbursement values were imputed based on the
assumption that the commitments were distributed evenly from the start date to the end date of the
project. The negative projects in IATI were corrected or removed by cross‐validating against CRS. The
duplicated projects were removed based on project identifiers. Consultations with several multilateral
donors were conducted to ensure the validity of the final data.

Fig. \@ref(fig:ePRESS) presents an example of how the new harmonised dataset looks after linking the different
sources. For the 15,312 projects in the new datasets, 54% of disbursement activities come from the
CRS data, compared with over 73% in the earlier dataset used for PRESS. In the new dataset, the PRESS
survey accounts for 27% of projects, while IATI data and donor databases account for 19% of projects.
By filtering through the data using recipient country and year, donors can already observe the
upcoming funding received by a country for statistical development. It is then easier for them to
identify funding gaps in prioritised areas. Hence, the new harmonised database can achieve better
diversification of data sources and reduce the dependence on CRS.

```{r ePRESS, echo=FALSE, fig.align="center", fig.cap = "Comparison of PRESS and the new harmonised database for the share of projects in the final data sets, by sources of data, 2016‐2018.", out.width= "80%" }
knitr::include_graphics("./images/ePRESS.png")
```


## Bringing them together – nowcasting and forecasting with the new harmonised database

PARIS21 applied the same model on nowcasting and forecasting support to statistics (disbursements)
but based on the new harmonised database, linking PRESS data with the aforementioned alternative
sources. The main findings of this approach were similar to those based on CRS estimations: there is
no indication of a systematic increase in funding to statistics in the current or coming years.

<!--chapter:end:04-Monitoring-funding-to-statistics-with-reduced-reporting-lag.Rmd-->

# Conclusion

The nowcast and forecast analysis aims to address the specific reporting lag issue faced by the PRESS,
rather than to substitute it. Even with longer lag, PRESS still reports the most reliable and
comprehensive data on funding to statistics. The PRESS database continues to serve as the source data
for SDG Indicator 17.19.1.

The outputs from nowcast and forecast also vary in their accuracy. While the merged database is as
robust as PRESS, and the nowcast results are relatively reliable, the forecast analysis is based on
several assumptions. Results produced through the nowcast and forecast analyses can therefore be
used for different products to serve different purposes:

  - The nowcast on disbursements and some information provided by the harmonised dataset
can be directly presented in PRESS going forward, as a natural extension of its current
content, based on existing data sources such as CRS.
  - The forecast for funding gaps could be presented in separate policy briefs due to its
speculative nature.
  - The complete, harmonised database can also be deployed on a platform such as Bern
Network’s [Clearinghouse for Financing Development Data](https://smartdatafinance.org) to be used as a dynamic
planning tool by development partners.

The immediate next step in improving the new methodology is to strengthen the communication and
consultation between PARIS21, donors, and recipients. Benefits from such consultations would lead
to further robust results by correcting erroneous information contained in IATI data, validating
assumptions on the termination or continuation of projects in assumptions for forecasting, and
enhancing data sharing in general. Consultations for this product will also help PARIS21 to shape its
work in order to better meet the demand of its stakeholders.

As the COVID‐19 pandemic will affect donors’ GNI and consequently their ODA, fluctuations in
development financing for data and statistics can be expected. Despite the difficulty these anomalies
will bring to the analyses, the transparency and timeliness of the information on funding to data and
statistics have also become more relevant, as identified in Part I of PRESS 2020. The results from these
analyses can play a crucial role in informing and supporting 

<!--chapter:end:05-Conclusion.Rmd-->

# References {-}

<div id="refs"></div>

<!--chapter:end:06-references.Rmd-->

# (APPENDIX) Appendix {-} 

# Appendix - Keyword lists {#Appendix-A}

## English {-}

```{r Appendix-A-en, echo=FALSE, message=FALSE, warning=FALSE, fig.pos = "!H"}
library(tidyverse)
library(kableExtra)
lang <- "en"
list_keywords_stat <- read_lines(paste0("./Data/Final keyword lists/statistics_reduced_", lang, ".txt"), skip_empty_rows = TRUE)  %>% trimws()
demining_small_arms <- read_lines(paste0("./Data/Final keyword lists/demining_small_arms_", lang, ".txt"), skip_empty_rows = TRUE)  %>% trimws()
list_acronyms <- read_lines(paste0("./Data/Final keyword lists/statistics_reduced_acronyms_", lang, ".txt"), skip_empty_rows = TRUE)  %>% trimws()
max <- max(length(list_keywords_stat), length(demining_small_arms), length(list_acronyms))
keywords <- data.frame(statistical_keywords = c(list_keywords_stat, rep("", max - length(list_keywords_stat))),
                          demining_keywords = c(demining_small_arms, rep("", max - length(demining_small_arms))),
                          acronyms = c(list_acronyms, rep("", max - length((list_acronyms)))))
knitr::kable(keywords[1:45,], row.names = F)%>% 
  kable_styling(font_size = 10, latex_options = "HOLD_position")
knitr::kable(keywords[45:nrow(keywords), ], row.names = F) %>% 
  kable_styling(font_size = 10, latex_options = "HOLD_position")
```
## French {-}

```{r Appendix-A-fr, echo=FALSE}
lang <- "fr"
list_keywords_stat <- read_lines(paste0("./Data/Final keyword lists/statistics_reduced_", lang, ".txt"), skip_empty_rows = TRUE)  %>% trimws()
demining_small_arms <- read_lines(paste0("./Data/Final keyword lists/demining_small_arms_", lang, ".txt"), skip_empty_rows = TRUE)  %>% trimws()
list_acronyms <- read_lines(paste0("./Data/Final keyword lists/statistics_reduced_acronyms_", lang, ".txt"), skip_empty_rows = TRUE)  %>% trimws()
max <- max(length(list_keywords_stat), length(demining_small_arms), length(list_acronyms))
keywords <- data.frame(statistical_keywords = c(list_keywords_stat, rep("", max - length(list_keywords_stat))),
                          demining_keywords = c(demining_small_arms, rep("", max - length(demining_small_arms))),
                          acronyms = c(list_acronyms, rep("", max - length((list_acronyms)))))
knitr::kable(keywords[1:45,], row.names = F)%>% 
  kable_styling(font_size = 10, latex_options = "HOLD_position")
knitr::kable(keywords[45:nrow(keywords), ], row.names = F) %>% 
  kable_styling(font_size = 10, latex_options = "HOLD_position")
```

## Spanish {-}

```{r Appendix-A-es, echo=FALSE}
lang <- "es"
list_keywords_stat <- read_lines(paste0("./Data/Final keyword lists/statistics_reduced_", lang, ".txt"), skip_empty_rows = TRUE)  %>% trimws()
demining_small_arms <- read_lines(paste0("./Data/Final keyword lists/demining_small_arms_", lang, ".txt"), skip_empty_rows = TRUE)  %>% trimws()
list_acronyms <- read_lines(paste0("./Data/Final keyword lists/statistics_reduced_acronyms_", lang, ".txt"), skip_empty_rows = TRUE)  %>% trimws()
max <- max(length(list_keywords_stat), length(demining_small_arms), length(list_acronyms))
keywords <- data.frame(statistical_keywords = c(list_keywords_stat, rep("", max - length(list_keywords_stat))),
                          demining_keywords = c(demining_small_arms, rep("", max - length(demining_small_arms))),
                          acronyms = c(list_acronyms, rep("", max - length((list_acronyms)))))
knitr::kable(keywords[1:45,], row.names = F)%>% 
  kable_styling(font_size = 10, latex_options = "HOLD_position")
knitr::kable(keywords[45:nrow(keywords), ], row.names = F) %>% 
  kable_styling(font_size = 10, latex_options = "HOLD_position")
```

## German {-}

```{r Appendix-A-de, echo=FALSE}
lang <- "de"
list_keywords_stat <- read_lines(paste0("./Data/Final keyword lists/statistics_reduced_", lang, ".txt"), skip_empty_rows = TRUE)  %>% trimws()
demining_small_arms <- read_lines(paste0("./Data/Final keyword lists/demining_small_arms_", lang, ".txt"), skip_empty_rows = TRUE)  %>% trimws()
list_acronyms <- read_lines(paste0("./Data/Final keyword lists/statistics_reduced_acronyms_", lang, ".txt"), skip_empty_rows = TRUE)  %>% trimws()
max <- max(length(list_keywords_stat), length(demining_small_arms), length(list_acronyms))
keywords <- data.frame(statistical_keywords = c(list_keywords_stat, rep("", max - length(list_keywords_stat))),
                          demining_keywords = c(demining_small_arms, rep("", max - length(demining_small_arms))),
                          acronyms = c(list_acronyms, rep("", max - length((list_acronyms)))))
knitr::kable(keywords[1:45,], row.names = F)%>% 
  kable_styling(font_size = 10, latex_options = "HOLD_position")
knitr::kable(keywords[45:nrow(keywords), ], row.names = F) %>% 
  kable_styling(font_size = 10, latex_options = "HOLD_position")
```

# Appendix - Performance tests {#Appendix-B}

```{r Appendix-B-precision, echo = FALSE, message=FALSE, fig.align='center', fig.cap='Precision, accuracy, recall and F1 score for the English classification', out.width='100%'}
knitr::include_graphics("./images/en_threshold_precision_accuracy_it1_1_n9482learning.png")
```

```{r Appendix-B-es-donor-learning, echo = FALSE, message=FALSE, fig.align='center', fig.cap='Donor distribution of the learning data for the Spanish classification.', out.width='100%'}
knitr::include_graphics("./images/es_hist_donorname_learning_data.png")
```

```{r Appendix-B-es-donor-pred, echo = FALSE, message=FALSE, fig.align='center', fig.cap='Donor distribution of the prediction data for the Spanish classification.', out.width='100%'}
knitr::include_graphics("./images/es_hist_donorname_pred_data.png")
```

<!--chapter:end:07-Appendix.Rmd-->

